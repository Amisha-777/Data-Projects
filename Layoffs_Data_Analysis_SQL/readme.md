# ğŸ“Š SQL Project: Layoffs Data Analysis

## ğŸ“Œ Project Overview

This project aims to analyze layoffs data using SQL, focusing on data cleaning, transformation, and exploratory data analysis (EDA) to extract meaningful insights.

## ğŸ“‚ Dataset
File Used: [layoffs.csv](https://github.com/Amisha-777/Data-Projects/blob/main/Layoffs_Data_Analysis_SQL/layoffs.csv)
Data Description: Contains layoff data from various companies, including company names, industries, total layoffs, and dates.

## ğŸ—ï¸ Project Structure
1ï¸âƒ£ Data Cleaning (data_cleaning (layoffs).sql)
- Handling missing values
- Standardizing data formats
- Removing duplicates
- Correcting inconsistencies in categorical values

2ï¸âƒ£ Exploratory Data Analysis (exploratory_data_analysis.sql)
- Summary statistics
- Industry-wise layoffs analysis
- Yearly and monthly trends
- Identifying top affected companies
- Regional layoffs comparison

## ğŸ› ï¸ Key SQL Techniques Used
- SELECT, WHERE, GROUP BY, ORDER BY
- Aggregate functions (COUNT, SUM, AVG)
- Joins and subqueries
- Window functions (RANK, DENSE_RANK)
- Common Table Expressions (CTEs)
- Data type conversions

## ğŸ” Key Insights
- Most affected industries by layoffs
- Seasonal trends in layoffs over time
- Top companies with the highest layoffs
- Regional distribution of layoffs

## ğŸš€ How to Use
1. Load the dataset into a SQL database.
2. Run data_cleaning (layoffs).sql to preprocess the data.
3. Execute exploratory_data_analysis.sql to generate insights.
4. Modify queries as needed for deeper analysis.

## ğŸ“ˆ Future Enhancements
- Integration with visualization tools like Tableau or Power BI
- Automating data pipeline for real-time layoff tracking
- Incorporating external datasets for enriched analysis
